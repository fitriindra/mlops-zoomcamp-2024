# Orchestration and ML Pipelines
## 3.1. Introduction: ML pipelines and Mage
### Machine Learning Pipeline
Using notebook and just executing the cell sequentially can be a disorganized way to do an experiment because we might forget to execute some cells in order. By using pipeline we can divide the experiment flow into several steps, such as:
- data ingestion
- data transformation: filtering, removing outliers, etc
- preparing data: splitting data for the model
- hyperparameter tuning
- train model

### Mage
#### Running Mage in Codespace

#### Running Mage with Docker

## 3.2. Data preparation: ETL and feature engineering
- Data Ingestion
- Utility
- Prepare
- Prepare chart
- Build encoders
- Build code
- Build test

## 3.3. Training: sklearn models and XGBoost
- GDP Training Set
- Sklearn training GDP
- Load models
- Load models utility
- Hyperparameter tuning
- Sklearn trained
- Hyperparameter XGBoost
- XGBoost trained

## 3.4. Observability: Monitoring and alerting
- Sklearn
- XGBoost
- Overview
- Time series bar
- Histogram
- Bar chart
- Pie chart
- Setup alerts
- Email

## 3.5. Triggering: Inference and retraining
- Retraining Pipepline
- Trigger
- Predict
- Inference notebook
- Interactions
- Interactions run
- API

## 3.6. Deploying: Running operations in production
- Setup email
- Deploy
- CI/CD
- Deployed

## Homework
> will be added later


